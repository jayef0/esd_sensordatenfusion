%---------------------------------------------------------------------------------------------------------------------------
% Kopf des Vortrags
%---------------------------------------------------------------------------------------------------------------------------

\part{Sensordatenfusion}
\begin{center}
Janfabian Fabriczek, \\ Geschwister-Scholl-Straße 15, 73732 Esslingen,\\ E-Mail: janfabian.fabriczek@stud.hs-esslingen.de \\[1cm] 18. April 2019 \\[1cm]
\end{center}


%---------------------------------------------------------------------------------------------------------------------------
% Textteil
%---------------------------------------------------------------------------------------------------------------------------
\section*{Einleitung und Motivation}

Das autonome Fahren hat für die Automobilbranche einen hohen Stellenwert. Ein Computer steuert das Automobil ohne menschlichen Einfluss. Damit der Computer im Automobil genau weiß, wie, wann und wo es fahren kann und muss, muss es die Umgebung wahrnehmen können.

Um die Umgebung wahrnehmen zu können, werden Sensoren am Automobil verwendet. In der Außenwelt gibt es viele verschiedene Wetterbedingungen, die die Sensoren so stark beeinflussen können, dass sie ihren Zweck nicht mehr erfüllen können. Der Einsatz mehrerer Sensoren mit unterschiedlichen Wahrnehmungsverfahren hilft dabei, die Blindheit des Automobils zu vermeiden und somit auch die Sicherheit neben der Funktionsfähigkeit zu gewährleisten.

Der Einsatz von mehreren Sensoren erfordert allerdings, dass die Messdaten zusammengefasst werden und unter Verwendung der zusammengefassten Messdaten ein komplettes Abbild der Umgebung erstellt wird. Unter dem Begriff \textit{Sensordatenfusion} wird das Zusammenführen der Sensordaten verstanden.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section*{Aufbau}

\subsection*{Allgemein}

Die einzelnen Sensoren sind über eine Verbindung mit dem Verarbeitungssystem verbunden \cite{Ref_WikiSDF}. Das Verarbeitungssystem fusioniert die Daten der einzelnen Sensoren \cite{Ref_WikiSDF}. Die Anwendungen greifen auf das Verarbeitungssystem zu, um die fusionierten Daten verwenden zu können \cite{Ref_WikiSDF}. Die zugreifende Anwendung kann basierend auf den vorhandenen Daten Entscheidungen treffen. In Abbildung \ref{Abb_AufbauSensordatenfusion} ist der Aufbau eines Systems zur Sensordatenfusion dargestellt.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{figure}[ht]
 \centerline{\includegraphics[width=0.41\textwidth]{Name_JFBR/aufbau_allgemein.png}}
 \caption {Aufbau eines Systems zur Sensordatenfusion \cite{Ref_WikiSDF}}
 \label{Abb_AufbauSensordatenfusion} 
\end{figure}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Die Sensoren werden für die \textit{Sensordatenfusion} nach einer bestimmten Strategie gewählt und angeordnet. Die einzelnen Strategien werden im Folgenden behandelt.

\subsection*{Sensoranordnung}

Die Sensoren werden in einem oder mehreren Sensornetzwerken angeordnet \cite{Ref_StuekerHomogeneSDF}.

Unter einem Sensornetzwerk wird der Verbund mehrerer gleicher oder auch unterschiedlicher Sensoren in einem Netzwerk verstanden.

Die Sensornetzwerke werden zwischen zwei Typen unterschieden \cite{Ref_StuekerHomogeneSDF}. Der eine Typ ist das homogene Sensornetzwerk und der andere Typ ist das heterogene Sensornetzwerk \cite{Ref_StuekerHomogeneSDF}.

In einem homogenen Sensornetzwerk verwenden alle Sensoren dasselbe physikalische Prinzip zum Messen. Die Sensoren in einem solchen Netzwerk unterliegen daher alle den gleichen Einschränkungen \cite{Ref_StuekerHomogeneSDF}.

In einem heterogenen Sensornetzwerk verwenden die Sensoren unterschiedliche physikalische Prinzipien zum Messen \cite{Ref_StuekerHomogeneSDF}. Die Sensoren in einem heterogenen Sensornetzwerk kompensieren die Einschränkungen einzelner Sensoren \cite{Ref_StuekerHomogeneSDF}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage


\section*{Funktionsweise}

\subsection*{Allgemein}

Die Fusion wird von einem Verarbeitungssystem unter der Verwendung von Algorithmen und mathematischen Verfahren durchgeführt. Bei der Fusion werden die Daten der einzelnen Sensoren synchronisiert, mehrere Eigenschaften zu neuen Eigenschaften zusammengefügt und einzelne Erfassungsbereiche zu einem größeren Erfassungsbereich zusammengefügt.

\subsection*{Fusionstypen}

Bei der Fusion wird zwischen Fusionstypen unterschieden. Der gewählte Fusionstyp hat Auswirkung auf die Sensorenauswahl und wofür die Messdaten der Sensoren bei der Fusion verwendet werden. Im Folgenden werden die einzelnen Typen erläutert.

\subsubsection*{Redundante und kompetitive Fusion}

Bei der redundanten oder auch kompetitiven Fusion geschieht die Sammlung der Daten zur Fusion durch den Einsatz mehrerer identischer Sensoren mit demselben Erfassungsbereich, die in einem Sensornetzwerk zusammengefügt sind \cite{Ref_StuekerHomogeneSDF}.

Da alle eingesetzten Sensoren denselben Erfassungsbereich haben, erhöht sich durch diesen Typ nicht der Gesamterfassungsbereich \cite{Ref_StuekerHomogeneSDF}.

Das Ziel dieses Typs ist die Erhöhung der Genauigkeit der Beobachtung und die Verbesserung der Ausfallsicherheit \cite{Ref_StuekerHomogeneSDF}. Die Erhöhung der Genauigkeit entsteht durch die weiteren Sensoren, die durch das Sensornetzwerk zur Fusion zur Verfügung stehen, die weitere Messwerte erfassen \cite{Ref_StuekerHomogeneSDF}. Die Ausfallsicherheit verbessert sich, da mehrere Sensoren denselben Erfassungsbereich erfassen und somit der Erfassungsbereich auch dann noch erfasst wird, wenn einzelne Sensoren ausfallen \cite{Ref_StuekerHomogeneSDF}.

\subsubsection*{Komplementäre Fusion}

Bei der komplementären Fusion haben die Erfassungsbereiche der Sensoren keine Überlappungsbereiche \cite{Ref_StuekerHomogeneSDF}. Dies bedeutet, dass sich der Gesamterfassungsbereich bei dieser Fusion vergrößert \cite{Ref_StuekerHomogeneSDF}. Es handelt sich auch dann um eine komplementäre Fusion, wenn sich die Merkmale unterscheiden, die durch die einzelnen Sensoren wahrgenommen werden \cite{Ref_StuekerHomogeneSDF}. Ein Merkmal kann beispielsweise die Breite eines Objekts sein \cite{Ref_StuekerHomogeneSDF}.

Die Erhöhung des Gesamterfassungsbereichs ist das Ziel dieses Fusionstypen \cite{Ref_StuekerHomogeneSDF}. Das Ziel ist allerdings gefährdet, wenn einzelne Sensoren in einer komplementären Fusion ausfallen, da jeder Sensor nur einen bestimmten Erfassungsbereich oder bestimmte Merkmale wahrnimmt \cite{Ref_StuekerHomogeneSDF}.

\subsubsection*{Kooperative Fusion}

Eine kooperative Fusion liegt vor, wenn aus Wahrnehmungen mehrerer Sensoren ein neues Merkmal entsteht \cite{Ref_StuekerHomogeneSDF}. Ein Beispiel hierfür ist die Triangulation der Position eines Objekts unter Verwendung der Beobachtung von zwei Sensoren, die die Entfernung messen \cite{Ref_StuekerHomogeneSDF}.

\subsubsection*{Unabhängige Fusion}

Bei der unabhängigen Fusion werden die Messdaten von mehreren Sensoren verarbeitet, allerdings werden die Daten, die verarbeitet wurden, nicht zusammengefügt \cite{Ref_WikiSDF}. Die Daten werden von dem Verarbeitungssystem jeweils separat verarbeitet \cite{Ref_WikiSDF}. Die unabhängige Fusion ist ein Spezialfall der \textit{Sensordatenfusion} \cite{Ref_WikiSDF}.

\subsubsection*{Kombinierte Fusion}

Die einzelnen betrachteten Fusionen haben jeweils Vor- und Nachteile. Um die jeweiligen Nachteile der verschiedenen Fusionen zu kompensieren, werden die Fusionen, redundante und kompetitive  Fusion, komplementäre  Fusion und kooperative  Fusion, miteinander kombiniert. Ein Beispiel für die kombinierte Fusion ist in Abbildung \ref{Abb_AutoSensorenKombinierteFusion} dargestellt. Die unabhängige Fusion wird an dieser Stelle nicht verwendet, da sie keine Vorteile mit sich bringt.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{figure}[ht]
 \centerline{\includegraphics[width=0.41\textwidth]{Name_JFBR/car_sensors.jpg}}
 \caption {Fusionstyp: Kombinierte Fusion am Auto \cite{Ref_AutonousDrivingCriticism}}
 \label{Abb_AutoSensorenKombinierteFusion} 
\end{figure}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Fusionsverfahren}

Die Fusion erfolgt nach einem bestimmten Verfahren. Das Verfahren ist abhängig von der Ebene, auf der die Fusion stattfinden soll. Im Folgenden werden die einzelnen Verfahren erläutert.

\subsubsection*{Fusion über Sensoren}

Die Fusion über Sensoren hinweg ist das Zusammenführen der Signale der einzelnen Sensoren, die das Gleiche messen \cite{Ref_KochMSDF}. Ein Beispiel hierfür ist das Messen der Temperatur \cite{Ref_KochMSDF}. Das Zusammenführen der Messsignale findet somit noch vor den eigentlichen Schritten der Signalverarbeitung statt \cite{Ref_KochMSDF}.

\subsubsection*{Fusion über Eigenschaften}

Bei der Fusion über Eigenschaften werden einzelne Eigenschaften, die durch Sensoren erfasst wurden, wie beispielsweise die Temperatur, der Druck und die Feuchtigkeit zusammengeführt, um aus den einzelnen Eigenschaften eine neue Eigenschaft zu ermitteln, wie beispielsweise in diesem Fall den Luftbrechungsindex zu ermitteln \cite{Ref_KochMSDF}.

\subsubsection*{Fusion über Bereiche}

Bei der Fusion über Bereiche erfassen mehrere Sensoren die gleiche Eigenschaft, aber in unterschiedlichen räumlichen Bereichen \cite{Ref_KochMSDF}. Die Daten der Sensoren werden zu einem Abbild fusioniert. Durch diese Fusion wird der Gesamtbereich der erfassten Eigenschaft vergrößert \cite{Ref_KochMSDF}.

\subsubsection*{Fusion über Zeit}

Bei der Fusion über die Zeit werden ältere Daten mit den aktuellen Daten kombiniert \cite{Ref_KochMSDF}. Ältere Daten können ältere Messdaten oder auch Daten von der Kalibrierung sein \cite{Ref_KochMSDF}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Vorteile}

Als erstes wird der Nachteil ausgeglichen, dass normalerweise nur ein Sensor verwendet wird. Bei der \textit{Sensordatenfusion} werden mehrere Sensoren eingesetzt. Dies hat den Vorteil, dass die Schätzgenauigkeit verbessert wird \cite{Ref_StuekerHomogeneSDF}. Des Weiteren wird der Gesamterfassungsbereich durch den Einsatz von mehreren Sensoren vergrößert \cite{Ref_StuekerHomogeneSDF}. 
Darüber hinaus wird auch eine Verbesserung der Ausfallsicherheit erreicht \cite{Ref_StuekerHomogeneSDF}. Dadurch dürfen einzelne Sensoren auch ausfallen \cite{Ref_StuekerHomogeneSDF}, ohne dass sie die Funktionsfähigkeit einschränken. Aber durch den Ausfall von Sensoren bei der \textit{Sensordatenfusion} kann sich die durch die \textit{Sensordatenfusion} verbesserte Schätzgenauigkeit und Robustheit wieder verschlechtern \cite{Ref_UniSiegenSensor}. Auch die gewonnene Robustheit des Gesamtsystems kann sich durch den Ausfall mehrere Sensoren verschlechtern, da unter Umständen Sensoren ausfallen, die unter bestimmten Umweltbedingungen besser arbeiten, als andere. Um die Ausfallsicherheit nicht zu gefährden, werden die Sensoren mit Redundanz ausgelegt \cite{Ref_StuekerHomogeneSDF}. Es bedeutet, dass Sensoren, die zwingend erforderlich für die Sicherheit oder die Funktionsfähigkeit sind, mehrfach im Sensornetzwerk eingebunden werden.

Durch den Einsatz von mehreren Sensoren, die unterschiedliche Wahrnehmungsverfahren verwenden, beispielsweise Radar und Laserabstandssensoren, können die unterschiedlichen Stärken der Wahrnehmungsverfahren zusammengeführt werden und verbessern die Wahrnehmung des Erfassungsbereichs. Die Nachteile einzelner Wahrnehmungsverfahren der Sensoren, die unter bestimmten Umweltbedingungen entstehen können, werden ausgeglichen, da die Wahrnehmung in solchen Fällen beispielsweise hauptsächlich durch einen oder mehrere andere Sensoren übernommen wird \cite{Ref_SDFquadrocopter}. Die Fähigkeit die Umgebung ausreichend zu erfassen, wird somit auch in für einzelne Sensoren schwierigen Situationen gewährleistet.

Durch die Verwendung mehrerer Sensoren, die nach unterschiedlichen Wahrnehmungsverfahren arbeiten, können mehr Informationen der Umgebung erfasst werden \cite{Ref_UniSiegenSensor}.

Die \textit{Sensordatenfusion} hat ebenfalls den Vorteil, dass günstigere Sensoren verwendet werden können. Ohne die \textit{Sensordatenfusion} müssen Sensoren verwendet werden, dessen Einschränkungen nicht problematisch für den eingesetzten Zweck sind. In diesen Fällen sind die Sensoren, die dann aber benötigt werden sehr teuer. Wenn mehrere einzelne Sensoren verwendet werden, können die Sensoren unter Berücksichtigung des physikalischen Prinzips zur Wahrnehmung so gewählt werden, dass Einschränkungen einzelner Sensoren durch andere Sensoren im System ausgeglichen werden können \cite{Ref_SDFquadrocopter}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Nachteile}

Umso mehr Sensoren verwendet werden sollen, desto schwieriger wird die Integration der Sensoren \cite{Ref_WikiSDF}. Gründe hierfür sind der erhöhte Aufwand für die Verkabelung, der weitere notwendige Platz für die Sensoren, sowie die Versorgung der Sensoren mit Strom. Aus dem erhöhten Aufwand für die Verkabelung resultieren direkt steigende Kosten für die Verkabelung, um alle verbauten Sensoren einzubinden \cite{Ref_WikiSDF}.

Mit der Anzahl der Sensoren steigen ebenfalls die Datenmengen der Sensoren, die über die Kommunikationssysteme übertragen werden. In einigen Situationen wird versucht die Datentransferraten im Kommunikationssystem zu erhöhen \cite{Ref_WikiSDF}, damit die größere Datenmenge nicht für eine erhebliche Erhöhung der benötigten Zeit zur Übertragung der Daten an das Verarbeitungssystem.

Können die Datentransferraten nicht so stark erhöht werden, sodass der Mehraufwand für den Transfer der zusätzlichen Datenmengen ausgeglichen werden kann, entsteht ein deutlich erhöhter Zeitbedarf für die Übertragung der Daten der Sensoren zum Verarbeitungsziel \cite{Ref_WikiSDF}.

Umso mehr Daten entstehen und genutzt werden sollen, desto größer wird der Verarbeitungsaufwand. Der größere Verarbeitungsaufwand macht sich bemerkbar durch eine erhöhte Auslastung der Verarbeitungssysteme. Die erhöhte Auslastung kann dann, wenn nicht genügend Rechenleistung verfügbar ist, zu erheblich erhöhten Zeitverzögerungen führen.

Da nicht alle Sensoren die Umgebung zum gleichen Zeitpunkt erfassen und sich auch die Abtastzeiten gegebenenfalls unterscheiden, muss das Verarbeitungssystem einen erheblichen zusätzlichen Aufwand betreiben, um die Daten der einzelnen unterschiedlichen Sensoren zu synchronisieren \cite{Ref_WikiSDF}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section*{Einsatzgebiete}

Die \textit{Sensordatenfusion} wird in vielen Bereichen eingesetzt. Vor allem in den Bereichen des autonomen Fahrens und des autonomen Fliegens hat es eine hohe Bedeutung. In diesen beiden Bereichen werden hohe und auch sicherheitskritische Anforderungen an die maschinelle Erfassung der Umgebung gestellt. Die Anforderungen gestatten die Verwendung eines einzelnen Sensors nicht mehr.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage

%------------------------------------------------------------------------------------------------------------------------
\section*{Zusammenfassung}

Die \textit{Sensordatenfusion} ermöglicht es, Daten der verwendeten Sensoren auf unterschiedlichen Ebenen zusammenzuführen. Dies ermöglicht eine umfassendere oder auch genauere Erfassung der Umgebung und die Ermittlung von Merkmalen, die nicht erfasst werden können bzw. nur schwer erfasst werden können. Diese Verbesserung ist allerdings nur zu Lasten der Komplexität und des erhöhten Aufwands möglich. Die \textit{Sensordatenfusion} wird dort eingesetzt, wo die Anforderungen nicht mehr durch einen einzelnen Sensor erfüllt werden können und wenn es einen Sensor gibt, der die Anforderungen erfüllen kann, die Kosten des Sensors sehr hoch sind.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{}

\bibitem{Ref_WikiSDF}
Wikipedia, Online Nachschlagewerk: \textit{"'Sensordatenfusion"'},\\  \href{https://de.wikipedia.org/wiki/Sensordatenfusion}{https://de.wikipedia.org/wiki/Sensordatenfusion}, April 2019

\bibitem{Ref_StuekerHomogeneSDF}
Stüker, Dirk: \textit{"'Heterogene Sensordatenfusion zur robusten Objektverfolgung im automobilen Straßenverkehr"'},\\  \href{https://d-nb.info/972494464/34}{https://d-nb.info/972494464/34}, April 2019

\bibitem{Ref_AutonousDrivingCriticism}
Ptock, Julia: \textit{"'Autonomes Fahren: Verbraucherschutz kritisiert Gesetzesentwurf der Regierung"'},\\  \href{https://www.logistik-watchblog.de/neuheiten/844-autonomes-fahren-verbraucherschutz-kritisiert-gesetzesentwurf.html}{https://www.logistik-watchblog.de/neuheiten/844-autonomes-fahren-verbraucherschutz-kritisiert-gesetzesentwurf.html}, April 2019

\bibitem{Ref_KochMSDF}
Mitchell, Harvey B.: \textit{"'Multi-Sensor Data Fusion: An Introduction"'},\\  \href{https://d-nb.info/972494464/34}{https://d-nb.info/972494464/34}, 1. Auflage, Springer Berlin Heidelberg, 2007

\bibitem{Ref_UniSiegenSensor}
Universität-GH Siegen, Zentrum für Sensorsysteme: \textit{"'Sensordatenfusion mit Kalman-Filtern Optimale Informationsverarbeitung"'},\\  \href{https://www.uni-siegen.de/zess/profil/929604.pdf}{https://www.uni-siegen.de/zess/profil/929604.pdf}, April 2019

\bibitem{Ref_SDFquadrocopter}
Lange, Sven: \textit{"'Faktorgraph-basierte Sensordatenfusion zur Anwendung auf einem Quadrocopter"'},\\  \href{http://www.qucosa.de/fileadmin/data/qucosa/documents/13057/diss\_lasve\_final.pdf}{http://www.qucosa.de/fileadmin/data/qucosa/documents /13057/diss\_lasve\_final.pdf}, April 2019


\end{thebibliography}


%---------------------------------------------------------------------------------------------------------------------------
% Kopf des Vortrags
%---------------------------------------------------------------------------------------------------------------------------

\part{Sensordatenfusion}
\begin{center}
Janfabian Fabriczek, \\ Geschwister-Scholl-Straße 15, 73732 Esslingen,\\ E-Mail: janfabian.fabriczek@stud.hs-esslingen.de \\[1cm] 01. April 2019 \\[1cm]
\end{center}


%---------------------------------------------------------------------------------------------------------------------------
% Textteil
%---------------------------------------------------------------------------------------------------------------------------
\section*{Einleitung}
\label{Kap_Einleitung}

Das autonome Fahren hat für die Automobilbranche einen hohen Stellenwert. Ein Computer steuert das Auto ohne menschlichen Einfluss. Damit der Computer im Auto genau weiß wie, wann und wo es fahren kann und muss, muss es die Umgebung wahrnehmen können.

Um die Umgebung wahrnehmen zu können, werden Sensoren am Auto verwendet. In der Außenwelt gibt es viele verschiedene Wetterbedingungen, die die Sensoren so stark beeinflussen können, dass sie ihren Zweck nicht mehr erfüllen können. Der Einsatz mehrerer Sensoren mit unterschiedlichen Wahrnehmungsverfahren hilft, die Blindheit des Autos zu vermeiden und somit auch die Sicherheit neben der Funktionsfähigkeit zu gewährleisten.

Der Einsatz von mehreren Sensoren erfordert allerdings, dass die Messdaten zusammengefasst werden und unter Verwendung der zusammengefassten Messdaten ein komplettes Abbild der Umgebung erstellt wird. Unter dem Begriff \textit{Sensordatenfusion} wird das Zusammenführen der Sensordaten verstanden.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Aufbau}

\subsection*{Allgemein}

Die einzelnen Sensoren sind über eine Verbindung mit dem Verarbeitungssystem verbunden. Das Verarbeitungssystem fusioniert die Daten der einzelnen Sensoren. Die Anwendungen greifen auf das Verarbeitungssystem zu, um die fusionierten Daten verwenden zu können. Die zugreifende Anwendung kann basierend auf den vorhandenen Daten Entscheidungen treffen. In Abbildung x ist der Aufbau eines Systems zur Sensordatenfusion dargestellt.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{figure}[ht]
 \centerline{\includegraphics[width=0.41\textwidth]{Name_JFBR/aufbau_allgemein.png}}
 \caption {Aufbau eines Systems zur Sensordatenfusion}
\end{figure}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Die Sensoren werden für die Sensordatenfusion nach einer bestimmten Strategie gewählt. Die einzelnen Strategien werden im Folgenden behandelt.

\subsection*{Sensoranordnung}

Unter einem Sensornetzwerk wird der Verbund mehrerer gleicher oder auch unterschiedlicher Sensoren in einem Netzwerk verstanden.

Die Sensornetzwerke werden zwischen zwei Typen unterschieden. Der eine Typ ist das homogene Sensornetzwerk und der andere Typ ist das heterogene Sensornetzwerk. In einem homogenen Sensornetzwerk verwenden alle Sensoren dasselbe physikalische Prinzip zum Messen. Die Sensoren in einem solchen Netzwerk unterliegen somit alle den gleichen Einschränkungen.

In einem heterogenen Sensornetzwerk verwenden die Sensoren unterschiedliche physikalische Prinzipien zum Messen. Die Sensoren in einem heterogenen Sensornetzwerk kompensieren die Einschränkungen einzelner Sensoren.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Sensorkonfiguration}

Bei der Fusion wird zwischen verschiedenen Typen unterschieden. Im Folgenden werden die einzelnen Fusionstypen dargestellt.

\subsubsection*{Redundante und kompetitive  Fusion}

Bei der redundanten oder auch kompetitiven Fusion geschieht die Sammlung der Daten zur Fusion durch den Einsatz mehrerer identischer Sensoren mit demselben Erfassungsbereich, die in einem Sensornetzwerk zusammengefügt sind.

Da alle eingesetzten Sensoren denselben Erfassungsbereich haben, erhöht sich durch diesen Fusionstyp nicht der Gesamterfassungsbereich.

Das Ziel dieses Fusionstyps ist die Erhöhung der Genauigkeit der Beobachtung und die Verbesserung der Ausfallsicherheit. Die Erhöhung der Genauigkeit resultiert durch die weiteren Sensoren, die durch das Sensornetzwerk der Fusion zur Verfügung stehen, die weitere Messwerte erfassen. Die Ausfallsicherheit verbessert sich, da mehrere Sensoren denselben Bereich erfassen und somit der Bereich auch dann noch erfasst wird, wenn mehrere Sensoren ausfallen. 

\subsubsection*{Komplementäre  Fusion}

Bei der komplementären Fusion haben die Erfassungsbereiche der Sensoren keine Überlappungsbereiche. Dies bedeutet, dass sich der Gesamterfassungsbereich bei dieser Fusion vergrößert. Es handelt sich auch dann um eine komplementäre Fusion, wenn sich die Merkmale unterscheiden, die durch die einzelnen Sensoren wahrgenommen werden. Ein Merkmal kann beispielsweise die Breite eines Objekts sein.

Die Erhöhung des Gesamterfassungsbereichs ist das Ziel dieses Fusionstypen. Das Ziel ist allerdings gefährdet, wenn einzelne Sensoren in einer komplementären Fusion ausfallen, da jeder Sensor nur einen bestimmten Erfassungsbereich oder bestimmte Merkmale wahrnimmt.

\subsubsection*{Kooperative  Fusion}

Eine kooperative Fusion liegt vor, wenn aus Wahrnehmungen mehrerer Sensoren ein neues Merkmal entsteht. Ein Beispiel hierfür ist die Triangulation der Position eines Objekts unter Verwendung der Beobachtung von zwei Sensoren, die die Entfernung messen.

\subsubsection*{Unabhängige Fusion}

Bei der unabhängigen Fusion werden die Messdaten von mehreren Sensoren verarbeitet, allerdings werden die Daten, die verarbeitet wurden, nicht zusammengefügt. Die Daten werden von dem Verarbeitungssystem separat verarbeitet. Die unabhängige Fusion ist ein Spezialfall der Sensordatenfusion.

\subsubsection*{Kombinierte Fusion}

Die einzelnen betrachteten Fusionen haben jeweils Vor- und Nachteile. Um die jeweiligen Nachteile der verschiedenen Fusionen zu kompensieren, werden die Fusionen, redundante und kompetitive  Fusion, komplementäre  Fusion und kooperative  Fusion, miteinander kombiniert. Die unabhängige Fusion wird an dieser Stelle nicht verwendet, da sie keine Vorteile mit sich bringt.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{figure}[ht]
 \centerline{\includegraphics[width=0.41\textwidth]{Name_JFBR/car_sensors.jpg}}
 \caption {Sensorkonfiguration: Kombinierte Fusion am Auto}
\end{figure}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage


\section*{Funktionsweise}

\subsection*{Allgemein}

Die Fusion wird von einem Verarbeitungssystem unter der Verwendung von Algorithmen und mathematischen Verfahren durchgeführt. Bei der Fusion werden die Daten der einzelnen Sensoren synchronisiert, mehrere Eigenschaften zu neuen Eigenschaften zusammengefügt und einzelne Erfassungsbereiche zu einem größeren Erfassungsbereich zusammengefügt.

\subsection*{Fusionsverfahren}

Die unterschiedlichen Fusionsverfahren werden im Folgenden im Detail betrachtet.

\subsubsection*{Fusion über Sensoren}

Die Fusion über Sensoren hinweg ist das Zusammenführen der Signale der einzelnen Sensoren, die das Gleiche messen. Ein Beispiel hierfür ist das Messen der Temperatur. Das Zusammenführen der Messsignale findet somit noch vor den eigentlichen Schritten der Signalverarbeitung statt.

\subsubsection*{Fusion über Eigenschaften}

Bei der Fusion über Eigenschaften werden einzelne Eigenschaften, die durch Sensoren erfasst wurden, wie beispielsweise die Temperatur, der Druck und die Feuchtigkeit zusammengeführt, um aus den einzelnen Eigenschaften eine neue Eigenschaft zu ermitteln, wie beispielsweise in diesem Fall den Luftbrechungsindex zu ermitteln.

\subsubsection*{Fusion über Bereiche}

Bei der Fusion über Bereiche erfassen mehrere Sensoren die gleiche Eigenschaft, aber in unterschiedlichen räumlichen Bereichen. Die Messdaten der Sensoren werden zu einem Abbild fusioniert. Durch diese Fusion wird der Gesamtbereich der erfassten Eigenschaft vergrößert.

\subsubsection*{Fusion über Zeit}

Bei der Fusion über die Zeit werden ältere Daten mit den aktuellen Messdaten kombiniert. Ältere Daten können ältere Messdaten oder auch Daten von der Kalibrierung sein.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Vorteile}

Als erstes wird der Nachteil ausgeglichen, dass normalerweise nur ein Sensor verwendet wird. Bei der Sensordatenfusion werden mehrere Sensoren eingesetzt. Dies hat den Vorteil, dass die Schätzgenauigkeit verbessert wird. Des Weiteren wird der Gesamterfassungsbereich durch den Einsatz von mehreren Sensoren vergrößert. 
Darüber hinaus wird auch eine Verbesserung der Ausfallsicherheit erreicht. Dadurch dürfen einzelne Sensoren auch ausfallen, ohne dass sie die Funktionsfähigkeit einschränken. Aber durch den Ausfall von Sensoren bei der Sensordatenfusion kann sich die durch die Sensordatenfusion verbesserte Schätzgenauigkeit und Robustheit wieder verschlechtern. Auch die gewonnene Robustheit des Gesamtsystems kann sich durch den Ausfall mehrere Sensoren verschlechtern, da unter Umständen Sensoren ausfallen, die unter bestimmten Umweltbedingungen besser arbeiten, als andere. Um die Ausfallsicherheit nicht zu gefährden, werden die Sensoren mit Redundanz ausgelegt. Es bedeutet, dass Sensoren, die zwingend erforderlich für die Sicherheit oder die Funktionsfähigkeit sind, mehrfach im Sensornetzwerk eingebunden werden.

Durch den Einsatz von mehreren Sensoren, die unterschiedliche Wahrnehmungsverfahren verwenden, beispielsweise Radar und Laserabstandssensoren, können die unterschiedlichen Stärken der Wahrnehmungsverfahren zusammengeführt werden und verbessern die Wahrnehmung des Erfassungsbereichs. Die Nachteile einzelner Wahrnehmungsverfahren der Sensoren, die unter bestimmten Umweltbedingungen entstehen können, werden ausgeglichen, da die Wahrnehmung in solchen Fällen beispielsweise hauptsächlich durch einen oder mehrere andere Sensoren übernommen wird. Die Fähigkeit die Umgebung ausreichend zu erfassen, wird somit auch in für einzelne Sensoren schwierigen Situationen gewährleistet.

Durch die Verwendung mehrerer Sensoren, die nach unterschiedlichen Wahrnehmungsverfahren arbeiten, können mehr Informationen der Umgebung erfasst werden.

Die Sensordatenfusion hat ebenfalls den Vorteil, dass günstigere Sensoren verwendet werden können. Ohne die Sensordatenfusion müssen Sensoren verwendet werden, dessen Einschränkungen nicht problematisch für den eingesetzten Zweck sind. In diesen Fällen sind die Sensoren, die dann aber benötigt werden sehr teuer. Wenn mehrere einzelne Sensoren verwendet werden, können die Sensoren unter Berücksichtigung des physikalischen Prinzips zur Wahrnehmung so gewählt werden, dass Einschränkungen einzelner Sensoren durch andere Sensoren im System ausgeglichen werden können.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Nachteile}

Umso mehr Sensoren verwendet werden sollen, desto schwieriger wird die Integration der Sensoren. Gründe hierfür sind der erhöhte Aufwand für die Verkabelung, der weitere notwendige Platz für die Sensoren, sowie die Versorgung der Sensoren mit Strom. Aus dem erhöhten Aufwand für die Verkabelung resultieren direkt steigende Kosten für die Verkabelung, um alle verbauten Sensoren einzubinden.

Mit der Anzahl der Sensoren steigen ebenfalls die Datenmengen der Sensoren, die über die Kommunikationssysteme übertragen werden. In einigen Situationen wird versucht die Datentransferraten im Kommunikationssystem zu erhöhen, damit die größere Datenmenge nicht für eine erhebliche Erhöhung der benötigten Zeit zur Übertragung der Daten an das Verarbeitungssystem. 

Können die Datentransferraten nicht so stark erhöht werden, sodass der Mehraufwand für den Transfer der zusätzlichen Datenmengen ausgeglichen werden kann, entsteht ein deutlich erhöhter Zeitbedarf für die Übertragung der Daten der Sensoren zum Verarbeitungsziel.

Umso mehr Daten entstehen und genutzt werden sollen, desto größer wird der Verarbeitungsaufwand. Der größere Verarbeitungsaufwand macht sich bemerkbar durch eine erhöhte Auslastung der Verarbeitungssysteme. Die erhöhte Auslastung kann dann, wenn nicht genügend Rechenleistung verfügbar ist, zu erheblich erhöhten Zeitverzögerungen führen.

Da nicht alle Sensoren die Umgebung zum gleichen Zeitpunkt erfassen und sich auch die Abtastzeiten gegebenenfalls unterscheiden, muss das Verarbeitungssystem einen erheblichen zusätzlichen Aufwand betreiben, um die Daten der einzelnen unterschiedlichen Sensoren zu synchronisieren.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Einsatzgebiete}

Die Sensordatenfusion wird in vielen Bereichen eingesetzt. Vor allem in den Bereichen des autonomen Fahrens und des autonomen Fliegens hat es eine hohe Bedeutung. In diesen beiden Bereichen werden hohe und auch sicherheitskritische Anforderungen an die maschinelle Erfassung der Umgebung gestellt. Die Anforderungen gestatten die Verwendung eines einzelnen Sensors nicht mehr.

Im Folgenden werden drei Einsatzgebiete im Detail betrachtet.

\subsection*{Objekterkennung}

\subsection*{Positionsermittlung}

\subsection*{Fahrerassistenzsysteme}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage

%------------------------------------------------------------------------------------------------------------------------
\section*{Zusammenfassung}

Cras sagittis, ligula quis condimentum laoreet, lacus nisl pretium ligula, sed rutrum ipsum erat in dui. Nam hendrerit velit in dui laoreet, sed eleifend libero commodo. Vivamus pharetra lacus ac viverra hendrerit. Pellentesque dignissim tempus tempor. Nullam sit amet justo libero.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{}

\bibitem{Ref_PGN07}
Wikipedia, Online Nachschlagewerk: \textit{"'Primary Guidance, Navigation and Control System"'},\\  \href{http://de.wikipedia.org/wiki/Primary\_Guidance\%2C\_Navigation\_and\_Control\_System}{http://de.wikipedia.org/wiki/Primary\_Guidance\\\%2C\_Navigation \_and\_Control\_System}, Okt. 2007

\bibitem{Ref_WEN00}
Wenzel, L.: \textit{"'Kalman-Filter - Ein mathematisches Modell zur Auswertung von Messdaten für Regelungstechnik, Teil 1"'}, Elektronik 6/2000

\bibitem{Ref_Matrix2008}
Petersen, K. B., Petersen, M. S.: \textit{"'The Matrix Cookbook"'}, http://matrixcookbook.com, Version: November 14, 2008

\bibitem{Ref_Bronstein}
Bronstein, I. N., Semendjajew, K. A.: \textit{"'Taschenbuch der Mathematik"'}, 25. Auflage, Verlag Nauka, Moskau, B.G. Teubner Verlagsgesellschaft Stuttgart, Leipzig, Verlag Harri Deutsch Thun und Frankfurt/Main, 1991

\bibitem{Ref_Kalman1960}
Kalman, R. E.: \textit{"'A New Approach to Linear Filtering and Prediction Problems"'}, Transaction of the ASME, Journal of Basic Engineering, Seiten 35-45, 1960

\bibitem{Ref_GRE01}
Grewal, M. S. und Andrews, P. A.: \textit{"'Kalman filtering: theory and practice using Matlab"'}, second edition, Wiley-Interscience Publication, New York, 2001

\end{thebibliography}


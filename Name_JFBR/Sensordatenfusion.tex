%---------------------------------------------------------------------------------------------------------------------------
% Kopf des Vortrags
%---------------------------------------------------------------------------------------------------------------------------

\part{Sensordatenfusion}
\begin{center}
Janfabian Fabriczek, \\ Geschwister-Scholl-Straße 15, 73732 Esslingen,\\ E-Mail: janfabian.fabriczek@stud.hs-esslingen.de \\[1cm] 01. April 2019 \\[1cm]
\end{center}


%---------------------------------------------------------------------------------------------------------------------------
% Textteil
%---------------------------------------------------------------------------------------------------------------------------
\section*{Einleitung}
\label{Kap_Einleitung}

Das autonome Fahren hat für die Automobilbranche einen hohen Stellenwert. Ein Computer steuert das Auto ohne menschlichen Einfluss. Damit der Computer im Auto genau weiß wie, wann und wo es fahren kann und muss, muss es die Umgebung wahrnehmen können.

Um die Umgebung wahrnehmen zu können, werden Sensoren am Auto verwendet. In der Außenwelt gibt es viele verschiedene Wetterbedingungen, die die Sensoren so stark beeinflussen können, dass sie ihren Zweck nicht mehr erfüllen können. Der Einsatz mehrerer Sensoren mit unterschiedlichen Wahrnehmungsverfahren hilft, die Blindheit des Autos zu vermeiden und somit auch die Sicherheit neben der Funktionsfähigkeit zu gewährleisten.

Der Einsatz von mehreren Sensoren erfordert allerdings, dass die Messdaten zusammengefasst werden und unter Verwendung der zusammengefassten Messdaten ein komplettes Abbild der Umgebung erstellt wird. Unter dem Begriff \textit{Sensordatenfusion} wird das Zusammenführen der Sensordaten verstanden.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Funktionsweise}

\subsection*{Aufbau}

\subsubsection*{Allgemein}

Quisque sed luctus orci. Nam sodales massa ante, eget lacinia sapien mattis eu. Donec turpis

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{figure}[ht]
 \centerline{\includegraphics[width=0.41\textwidth]{Name_JFBR/aufbau_allgemein.png}}
 \caption {Condimentum laoreet, lacus nisl pretium}
\end{figure}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


\subsubsection*{Sensoren}

Unter einem Sensornetzwerk wird der Verbund mehrerer gleicher oder auch unterschiedlicher Sensoren in einem Netzwerk verstanden.

Die Sensornetzwerke werden zwischen zwei Typen unterschieden. Der eine Typ ist das homogene Sensornetzwerk und der andere Typ ist das heterogene Sensornetzwerk. In einem homogenen Sensornetzwerk verwenden alle Sensoren dasselbe physikalische Prinzip zum Messen. Die Sensoren in einem solchen Netzwerk unterliegen somit alle den gleichen Einschränkungen.

In einem heterogenen Sensornetzwerk verwenden die Sensoren unterschiedliche physikalische Prinzipien zum Messen. Die Sensoren in einem heterogenen Sensornetzwerk kompensieren die Einschränkungen 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\subsection*{Fusionstyp}

Nullam eu fringilla libero, vel tristique enim. Quisque efficitur ut nunc vel facilisis. Morbi 

\subsubsection*{Across Sensors - Data Fusion}

Nunc pellentesque lacinia metus vehicula auctor. In congue purus diam, vel sollicitudin sapien 

\subsubsection*{Across Attributes - Feature Fusion}

Ut vehicula ultricies maximus. Morbi lacus quam, tincidunt at interdum in, aliquet tempus sem. 

\subsubsection*{Across Domains - Decision Fusion}

Donec venenatis eleifend turpis in mollis. Praesent id mi quis justo feugiat viverra. Sed 

\subsubsection*{Across Time}

Donec mi eros, laoreet sit amet libero eget, laoreet tempus eros. Nulla aliquet nulla nec nibh 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\subsection*{Methodik}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section*{Sensorkonfiguration}

Bei der Fusion wird zwischen verschiedenen Typen unterschieden. Im Folgenden werden die einzelnen Fusionstypen dargestellt.

\subsection*{Redundante und kompetitive  Fusion}

Bei der redundanten oder auch kompetitiven Fusion geschieht die Sammlung der Daten zur Fusion durch den Einsatz mehrerer identischer Sensoren mit demselben Erfassungsbereich, die in einem Sensornetzwerk zusammengefügt sind.

Da alle eingesetzten Sensoren denselben Erfassungsbereich haben, erhöht sich durch diesen Fusionstyp nicht der Gesamterfassungsbereich.

Das Ziel dieses Fusionstyps ist die Erhöhung der Genauigkeit der Beobachtung und die Verbesserung der Ausfallsicherheit. Die Erhöhung der Genauigkeit resultiert durch die weiteren Sensoren, die durch das Sensornetzwerk der Fusion zur Verfügung stehen, die weitere Messwerte erfassen. Die Ausfallsicherheit verbessert sich, da mehrere Sensoren denselben Bereich erfassen und somit der Bereich auch dann noch erfasst wird, wenn mehrere Sensoren ausfallen. 

\subsection*{Komplementäre  Fusion}

Bei der komplementären Fusion haben die Erfassungsbereiche der Sensoren keine Überlappungsbereiche. Dies bedeutet, dass sich der Gesamterfassungsbereich bei dieser Fusion vergrößert. Es handelt sich auch dann um eine komplementäre Fusion, wenn sich die Merkmale unterscheiden, die durch die einzelnen Sensoren wahrgenommen werden. Ein Merkmal kann beispielsweise die Breite eines Objekts sein.

Die Erhöhung des Gesamterfassungsbereichs ist das Ziel dieses Fusionstypen. Das Ziel ist allerdings gefährdet, wenn einzelne Sensoren in einer komplementären Fusion ausfallen, da jeder Sensor nur einen bestimmten Erfassungsbereich oder bestimmte Merkmale wahrnimmt.

\subsection*{Kooperative  Fusion}

Aenean mollis tortor malesuada metus tincidunt tempor. Quisque quis orci nec quam lacinia  

\subsection*{Unabhängige Fusion}

Aenean mollis tortor malesuada metus tincidunt tempor. Quisque quis orci nec quam lacinia 

\subsection*{Vermischte Fusion}

Die einzelnen betrachteten Fusionen haben jeweils Vor- und Nachteile. Um die jeweiligen Nachteile der verschiedenen Fusionen zu kompensieren, werden die Fusionen, redundante und kompetitive  Fusion, komplementäre  Fusion und kooperative  Fusion, miteinander kombiniert. Die unabhängige Fusion wird an dieser Stelle nicht verwendet, da sie keine Vorteile mit sich bringt.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\begin{figure}[ht]
 \centerline{\includegraphics[width=0.41\textwidth]{Name_JFBR/car_sensors.jpg}}
 \caption {Condimentum laoreet, lacus nisl pretium}
\end{figure}
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Vorteile}

Als erstes wird der Nachteil ausgeglichen, dass normalerweise nur ein Sensor verwendet wird. Bei der Sensordatenfusion werden mehrere Sensoren eingesetzt. Dies hat den Vorteil, dass die Schätzgenauigkeit verbessert wird. Des Weiteren wird der Gesamterfassungsbereich durch den Einsatz von mehreren Sensoren vergrößert. 
Darüber hinaus wird auch eine Verbesserung der Ausfallsicherheit erreicht. Dadurch dürfen einzelne Sensoren auch ausfallen, ohne dass sie die Funktionsfähigkeit einschränken. Aber durch den Ausfall von Sensoren bei der Sensordatenfusion kann sich die durch die Sensordatenfusion verbesserte Schätzgenauigkeit und Robustheit wieder verschlechtern. Auch die gewonnene Robustheit des Gesamtsystems kann sich durch den Ausfall mehrere Sensoren verschlechtern, da unter Umständen Sensoren ausfallen, die unter bestimmten Umweltbedingungen besser arbeiten, als andere. Um die Ausfallsicherheit nicht zu gefährden, werden die Sensoren mit Redundanz ausgelegt. Es bedeutet, dass Sensoren, die zwingend erforderlich für die Sicherheit oder die Funktionsfähigkeit sind, mehrfach im Sensornetzwerk eingebunden werden.

Durch den Einsatz von mehreren Sensoren, die unterschiedliche Wahrnehmungsverfahren verwenden, beispielsweise Radar und Laserabstandssensoren, können die unterschiedlichen Stärken der Wahrnehmungsverfahren zusammengeführt werden und verbessern die Wahrnehmung des Erfassungsbereichs. Die Nachteile einzelner Wahrnehmungsverfahren der Sensoren, die unter bestimmten Umweltbedingungen entstehen können, werden ausgeglichen, da die Wahrnehmung in solchen Fällen beispielsweise hauptsächlich durch einen oder mehrere andere Sensoren übernommen wird. Die Fähigkeit die Umgebung ausreichend zu erfassen, wird somit auch in für einzelne Sensoren schwierigen Situationen gewährleistet.

Durch die Verwendung mehrerer Sensoren, die nach unterschiedlichen Wahrnehmungsverfahren arbeiten, können mehr Informationen der Umgebung erfasst werden.

Die Sensordatenfusion hat ebenfalls den Vorteil, dass günstigere Sensoren verwendet werden können. Ohne die Sensordatenfusion müssen Sensoren verwendet werden, dessen Einschränkungen nicht problematisch für den eingesetzten Zweck sind. In diesen Fällen sind die Sensoren, die dann aber benötigt werden sehr teuer. Wenn mehrere einzelne Sensoren verwendet werden, können die Sensoren unter Berücksichtigung des physikalischen Prinzips zur Wahrnehmung so gewählt werden, dass Einschränkungen einzelner Sensoren durch andere Sensoren im System ausgeglichen werden können.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Nachteile}

Umso mehr Sensoren verwendet werden sollen, desto schwieriger wird die Integration der Sensoren. Gründe hierfür sind der erhöhte Aufwand für die Verkabelung, der weitere notwendige Platz für die Sensoren, sowie die Versorgung der Sensoren mit Strom. Aus dem erhöhten Aufwand für die Verkabelung resultieren direkt steigende Kosten für die Verkabelung, um alle verbauten Sensoren einzubinden.

Mit der Anzahl der Sensoren steigen ebenfalls die Datenmengen der Sensoren, die über die Kommunikationssysteme übertragen werden. In einigen Situationen wird versucht die Datentransferraten im Kommunikationssystem zu erhöhen, damit die größere Datenmenge nicht für eine erhebliche Erhöhung der benötigten Zeit zur Übertragung der Daten an das Verarbeitungssystem. 

Können die Datentransferraten nicht so stark erhöht werden, sodass der Mehraufwand für den Transfer der zusätzlichen Datenmengen ausgeglichen werden kann, entsteht ein deutlich erhöhter Zeitbedarf für die Übertragung der Daten der Sensoren zum Verarbeitungsziel.

Umso mehr Daten entstehen und genutzt werden sollen, desto größer wird der Verarbeitungsaufwand. Der größere Verarbeitungsaufwand macht sich bemerkbar durch eine erhöhte Auslastung der Verarbeitungssysteme. Die erhöhte Auslastung kann dann, wenn nicht genügend Rechenleistung verfügbar ist, zu erheblich erhöhten Zeitverzögerungen führen.

Da nicht alle Sensoren die Umgebung zum gleichen Zeitpunkt erfassen und sich auch die Abtastzeiten gegebenenfalls unterscheiden, muss das Verarbeitungssystem einen erheblichen zusätzlichen Aufwand betreiben, um die Daten der einzelnen unterschiedlichen Sensoren synchronisieren.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section*{Einsatzgebiete}

Die Sensordatenfusion wird in vielen Bereichen eingesetzt. Vor allem in den Bereichen des autonomen Fahrens und des autonomen Fliegens hat es eine hohe Bedeutung. In diesen beiden Bereichen werden hohe und auch sicherheitskritische Anforderungen an die maschinelle Erfassung der Umgebung gestellt. Die Anforderungen gestatten die Verwendung eines einzelnen Sensors nicht mehr.

Im Folgenden werden drei Einsatzgebiete im Detail betrachtet.

\subsection*{Objekterkennung}

\subsection*{Positionsermittlung}

\subsection*{Fahrerassistenzsysteme}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage

%------------------------------------------------------------------------------------------------------------------------
\section*{Zusammenfassung}

Cras sagittis, ligula quis condimentum laoreet, lacus nisl pretium ligula, sed rutrum ipsum erat in dui. Nam hendrerit velit in dui laoreet, sed eleifend libero commodo. Vivamus pharetra lacus ac viverra hendrerit. Pellentesque dignissim tempus tempor. Nullam sit amet justo libero.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{}

\bibitem{Ref_PGN07}
Wikipedia, Online Nachschlagewerk: \textit{"'Primary Guidance, Navigation and Control System"'},\\  \href{http://de.wikipedia.org/wiki/Primary\_Guidance\%2C\_Navigation\_and\_Control\_System}{http://de.wikipedia.org/wiki/Primary\_Guidance\\\%2C\_Navigation \_and\_Control\_System}, Okt. 2007

\bibitem{Ref_WEN00}
Wenzel, L.: \textit{"'Kalman-Filter - Ein mathematisches Modell zur Auswertung von Messdaten für Regelungstechnik, Teil 1"'}, Elektronik 6/2000

\bibitem{Ref_Matrix2008}
Petersen, K. B., Petersen, M. S.: \textit{"'The Matrix Cookbook"'}, http://matrixcookbook.com, Version: November 14, 2008

\bibitem{Ref_Bronstein}
Bronstein, I. N., Semendjajew, K. A.: \textit{"'Taschenbuch der Mathematik"'}, 25. Auflage, Verlag Nauka, Moskau, B.G. Teubner Verlagsgesellschaft Stuttgart, Leipzig, Verlag Harri Deutsch Thun und Frankfurt/Main, 1991

\bibitem{Ref_Kalman1960}
Kalman, R. E.: \textit{"'A New Approach to Linear Filtering and Prediction Problems"'}, Transaction of the ASME, Journal of Basic Engineering, Seiten 35-45, 1960

\bibitem{Ref_GRE01}
Grewal, M. S. und Andrews, P. A.: \textit{"'Kalman filtering: theory and practice using Matlab"'}, second edition, Wiley-Interscience Publication, New York, 2001

\end{thebibliography}

